{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bootcamp Day 2.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "UO_e4YzCIIY6"
      },
      "source": [
        "# from https://dataverse.harvard.edu/dataset.xhtml?id=3047332\n",
        "!wget -O tweets.csv https://dataverse.harvard.edu/api/access/datafile/:persistentId?persistentId=doi:10.7910/DVN/JBXKFD/F4FULO\n",
        "!pip install transformers torch emoji"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xiPnFLl_HFQ1"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from transformers import AutoModel, AutoTokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Ua_dRmRB0yk"
      },
      "source": [
        "tweets_df = pd.read_csv(\"tweets.csv\")\n",
        "tweets_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tr6k3V66CMoB"
      },
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"vinai/bertweet-base\", use_fast=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MKQM7L0-FCim"
      },
      "source": [
        "tweets = list(tweets_df['content'][:100])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oydhAntrCOp9"
      },
      "source": [
        "inputs = tokenizer(tweets, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "labels = torch.tensor(len(tweets_df['author'][:100])).unsqueeze(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EaNr0kGpHCJD"
      },
      "source": [
        "bertweet = AutoModel.from_pretrained(\"vinai/bertweet-base\")\n",
        "# input_ids = torch.tensor([tokenizer.encode(tweets[0])])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xtkg8GoVItm0"
      },
      "source": [
        "with torch.no_grad():\n",
        "    features = bertweet(inputs.input_ids)  # Models outputs are now tuples"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNuQ4NpsKqi4"
      },
      "source": [
        "max([len(tweet) for tweet in tweets])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8-8vjgmMEo2"
      },
      "source": [
        "features.pooler_output.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHDni4DiS1iT"
      },
      "source": [
        "## Create Dataset and DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WsQbM5lCH2TF"
      },
      "source": [
        "class Preprocessor():\n",
        "\n",
        "  def __init__(self):\n",
        "    self.tokenizer = AutoTokenizer.from_pretrained(\"vinai/bertweet-base\", use_fast=False)\n",
        "    self.bertweet = AutoModel.from_pretrained(\"vinai/bertweet-base\")\n",
        "\n",
        "  def preprocess(self, df):\n",
        "    inputs = tokenizer(tweets, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "    labels = torch.tensor(len(df['author'])).unsqueeze(0)\n",
        "\n",
        "    # Run forward pass to get embeddings\n",
        "    with torch.no_grad():\n",
        "      self.features = bertweet(inputs.input_ids)  # Models outputs are now tuples\n",
        "\n",
        "    # Get pooled embeddings \n",
        "    xs = features.pooler_output\n",
        "    ys = torch.tensor(len(tweets_df['author'][:100])).unsqueeze(0)\n",
        "    \n",
        "    return (xy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvsIJ2uGOZnA"
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from torchvision.io import read_image\n",
        "\n",
        "class TweetDataset(Dataset):\n",
        "    def __init__(self, df, size=1000):\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(\"vinai/bertweet-base\", use_fast=False)\n",
        "        self.bertweet = AutoModel.from_pretrained(\"vinai/bertweet-base\")\n",
        "\n",
        "        self.inputs = tokenizer(tweets, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "        self.labels = torch.tensor(len(df['author'])).unsqueeze(0)\n",
        "\n",
        "        embeddings = features.pooler_output\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        # Run forward pass to get embeddings\n",
        "        with torch.no_grad():\n",
        "          features = bertweet(self.inputs.input_ids)\n",
        "\n",
        "\n",
        "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
        "        image = read_image(img_path)\n",
        "        label = self.img_labels.iloc[idx, 1]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        if self.target_transform:\n",
        "            label = self.target_transform(label)\n",
        "\n",
        "        return image, label"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}